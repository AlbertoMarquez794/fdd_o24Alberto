{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripcion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos son notificaciones de dispositivos GPS en Mexico. En promedio generan notificaciones automatizadas cada 5 minutos si el carro esta encendido, y 30 si esta apagado.  \n",
    "\n",
    "Cada notificacion esta acompannada de un evento de lo que esta ocurriendo, y trae la latitud y longitud.  \n",
    "\n",
    "El objetico es predecir si un vehiculo esta siendo robado de acuerdo a sus notificaciones, por lo que el primer paso seria limpiar datos y hacer ingenieria de variables.\n",
    "\n",
    "Trata de hacerlo **lazy** si puedes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dummy_data(num_cars, start_time, end_time, working_hours_interval, non_working_hours_interval):\n",
    "    data = []\n",
    "\n",
    "    # Define the latitude and longitude ranges for Mexico\n",
    "    min_latitude, max_latitude = 14.5388, 32.7186\n",
    "    min_longitude, max_longitude = -118.4662, -86.7104\n",
    "\n",
    "    for car_id in range(num_cars):\n",
    "        current_time = start_time\n",
    "\n",
    "        # Generate random initial latitude and longitude for each car\n",
    "        latitude = random.uniform(min_latitude, max_latitude)\n",
    "        longitude = random.uniform(min_longitude, max_longitude)\n",
    "\n",
    "        while current_time < end_time:\n",
    "            if current_time.weekday() < 5 and 9 <= current_time.hour < 17:\n",
    "                # Working hours (Monday to Friday, 9 AM to 5 PM)\n",
    "                interval = working_hours_interval\n",
    "            else:\n",
    "                # Non-working hours\n",
    "                interval = non_working_hours_interval\n",
    "\n",
    "            # Generate notification with 99% probability\n",
    "            if random.random() < 0.99:\n",
    "                notification = random.choice([\"low_fuel\", \"tire_pressure\", \"engine_check\", None])\n",
    "                data.append((f\"car_{car_id}\", current_time.isoformat(), latitude, longitude, notification))\n",
    "\n",
    "            # Generate additional notifications between intervals\n",
    "            while True:\n",
    "                additional_interval = random.expovariate(1 / (interval / 2))\n",
    "                additional_time = current_time + timedelta(minutes=additional_interval)\n",
    "                if additional_time >= current_time + timedelta(minutes=interval):\n",
    "                    break\n",
    "                notification = random.choice([\"low_fuel\", \"tire_pressure\", \"engine_check\", None])\n",
    "                data.append((f\"car_{car_id}\", additional_time.isoformat(), latitude, longitude, notification))\n",
    "\n",
    "            # Update latitude and longitude for car movement\n",
    "            latitude += random.uniform(-0.01, 0.01)\n",
    "            longitude += random.uniform(-0.01, 0.01)\n",
    "\n",
    "            # Check if the car is among the 1% that can have 100 notifications within 5 minutes\n",
    "            if random.random() < 0.01:\n",
    "                burst_start_time = current_time + timedelta(minutes=random.uniform(0, interval))\n",
    "                burst_end_time = burst_start_time + timedelta(minutes=5)\n",
    "                while current_time < burst_end_time:\n",
    "                    notification = random.choice([\"low_fuel\", \"tire_pressure\", \"engine_check\", None])\n",
    "                    data.append((f\"car_{car_id}\", current_time.isoformat(), latitude, longitude, notification))\n",
    "                    current_time += timedelta(seconds=random.uniform(1, 10))\n",
    "\n",
    "            current_time += timedelta(minutes=interval)\n",
    "\n",
    "    # Create a Polars DataFrame from the generated data\n",
    "    df = pl.DataFrame(\n",
    "        {\n",
    "            \"car_id\": [record[0] for record in data],\n",
    "            \"timestamp\": [record[1] for record in data],\n",
    "            \"latitude\": [record[2] for record in data],\n",
    "            \"longitude\": [record[3] for record in data],\n",
    "            \"notification\": [record[4] for record in data],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df.lazy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive plan: (run LazyFrame.explain(optimized=True) to see the optimized plan)\n",
      "\n",
      "SLICE[offset: 0, len: 5]\n",
      "  DF [\"car_id\", \"timestamp\", \"latitude\", \"longitude\"]; PROJECT */5 COLUMNS; SELECTION: \"None\"\n"
     ]
    }
   ],
   "source": [
    "num_cars = 1000\n",
    "start_time = datetime(2023, 1, 1, 0, 0, 0)  # Start of the week\n",
    "end_time = start_time + timedelta(weeks=1)  # End of the week\n",
    "working_hours_interval = 5  # Interval of 5 minutes during working hours\n",
    "non_working_hours_interval = 30  # Interval of 30 minutes during non-working hours\n",
    "\n",
    "# Generate the dummy data\n",
    "data = generate_dummy_data(num_cars, start_time, end_time, working_hours_interval, non_working_hours_interval)\n",
    "\n",
    "# Print the first few rows of the generated data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convierte el `timestamp` que actualmente es string a formato de tiempo en polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/qnd7j8zs6t5c1561jkd532gh0000gn/T/ipykernel_50224/2972458008.py:7: DeprecationWarning: `days` is deprecated. It has been renamed to `total_days`.\n",
      "  (pl.col(\"date\").diff().dt.days().fill_none(0)).alias(\"days_diff\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Expr' object has no attribute 'fill_none'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mwith_columns(\n\u001b[1;32m      2\u001b[0m     pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_str\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrptime(pl\u001b[38;5;241m.\u001b[39mDate, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Calculate the difference in days for each notification\u001b[39;00m\n\u001b[1;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msort([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mwith_columns(\n\u001b[0;32m----> 7\u001b[0m     (\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdays\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_none\u001b[49m(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdays_diff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Expr' object has no attribute 'fill_none'"
     ]
    }
   ],
   "source": [
    "data = data.with_columns(\n",
    "    pl.col(\"date_str\").str.strptime(pl.Date, format=\"%Y-%m-%d\").alias(\"date\")\n",
    ")\n",
    "\n",
    "# Calculate the difference in days for each notification\n",
    "data = data.sort([\"user_id\", \"date\"]).with_columns(\n",
    "    (pl.col(\"date\").diff().dt.days().fill_none(0)).alias(\"days_diff\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ComputeError",
     "evalue": "conversion from `str` to `datetime[μs]` failed in column 'timestamp' for 6166192 out of 6264755 values: [\"2023-01-01T00:15:26.185264\", \"2023-01-01T00:13:08.580043\", … \"2023-01-07T23:45:37.033019\"]\n\nYou might want to try:\n- setting `strict=False` to set values that cannot be converted to `null`\n- using `str.strptime`, `str.to_date`, or `str.to_datetime` and providing a format string",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mComputeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/fdd_p24/.venv/lib/python3.9/site-packages/polars/lazyframe/frame.py:1816\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, no_optimization, streaming, background, _eager, **_kwargs)\u001b[0m\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;66;03m# Only for testing purposes atm.\u001b[39;00m\n\u001b[1;32m   1814\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mComputeError\u001b[0m: conversion from `str` to `datetime[μs]` failed in column 'timestamp' for 6166192 out of 6264755 values: [\"2023-01-01T00:15:26.185264\", \"2023-01-01T00:13:08.580043\", … \"2023-01-07T23:45:37.033019\"]\n\nYou might want to try:\n- setting `strict=False` to set values that cannot be converted to `null`\n- using `str.strptime`, `str.to_date`, or `str.to_datetime` and providing a format string"
     ]
    }
   ],
   "source": [
    "data.collect().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingenieria de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que va a entrar a un modelo de machine learning es encesario que todas las variables sean numericas, y esten en formnato tidy. Cada observacion en una fila, y cada variable en una columna. Por lo tanto se decidio crear estadisticos y agregar los datos a intervalos uniformes de `x` minutos.  \n",
    "\n",
    "Por ejemplo, colapsar toda la informacion que ocurrion en el intervalo, como el numero de notificaciones en esos 5 minutos, el promedio entre notificaciones, y el tipo de notificaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen varias formas de hacer esto, puedes hacerlo con `group_by` primero para crear las nuevas variables, o `group_by` (`rolling`, `dynamic`) usando operaciones sobre listas. Utiliza claude o chat_gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Crea una nueva variable que compute la diferencia de tiempo entre notificaciones del mismo vehiculo. Piensa como lo vas a hacer. Llama a esta variable `notification_time`\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/qnd7j8zs6t5c1561jkd532gh0000gn/T/ipykernel_53950/3083676444.py:2: DeprecationWarning: `days` is deprecated. It has been renamed to `total_days`.\n",
      "  (pl.col(\"date\").diff().dt.days().fill_none(0)).alias(\"days_diff\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Expr' object has no attribute 'fill_none'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39msort([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mwith_columns(\n\u001b[0;32m----> 2\u001b[0m     (\u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiff\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdays\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_none\u001b[49m(\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdays_diff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Group by user_id and calculate the rolling mean of the days_diff column\u001b[39;00m\n\u001b[1;32m      6\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mwith_columns(\n\u001b[1;32m      7\u001b[0m     pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdays_diff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrolling_mean(window_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mover(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrolling_mean_days_diff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Expr' object has no attribute 'fill_none'"
     ]
    }
   ],
   "source": [
    "data = data.sort([\"user_id\", \"date\"]).with_columns(\n",
    "    (pl.col(\"date\").diff().dt.days().fill_none(0)).alias(\"days_diff\")\n",
    ")\n",
    "\n",
    "# Group by user_id and calculate the rolling mean of the days_diff column\n",
    "data = data.with_columns(\n",
    "    pl.col(\"days_diff\").rolling_mean(window_size=2).over(\"user_id\").alias(\"rolling_mean_days_diff\")\n",
    ")\n",
    "\n",
    "result = data.groupby(\"user_id\").agg([\n",
    "    pl.col(\"rolling_mean_days_diff\").mean().alias(\"mean_rolling_days_diff\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Crea una nueva variable que compute la distancia que viajo el vehiculo desde la ultima notificacion. Llamala `distance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Crea intervalos de `x` minutos por carro. Como el numero de notificaciones en esos intervalos no es uniforme tienes que buscar funciones de polars especificas, pero ademas tienen que ser por vehiculo, pues tienen que ser del mismo. Revisa las funciones de `group_by` `dynamic` y `rolling`.\n",
    "   1. Computa la media, mediana, varianza, max y min de `notification_time` los intervalos de `x` minutos\n",
    "   2. Computa la media, mediana, varianza, max y min de `distance`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
